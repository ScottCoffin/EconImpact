---
title: "02-Multiple Implementation"
author: "Scott Coffin"
date: "1/5/2021"
output: html_document
---

While data is missing for unrestricted cash reserves, it may be possible to estimate this from other data. This may be easily visualized in a dot plot.

```{r}
allSmalls.requested.responded %>% 
  ggplot(aes(x = log10(cash_reserve_unrestricted), y = log10(cash_reserve_total), color = Fee_Code)) + 
  geom_point() +
  theme_minimal()
```

We can see discrete grouping of cash reserve (total and unrestricted) by fee code with community larges (C1) and disadvantaged community larges have higher cash reserves, while small community (SC) and disadvantaged small communities have lower cash reserves. There also seems to be a clear relationship between these variables, with some highly significant outliers. Independent linear regression models may be used to predict missing data, however more sophisticated methods are likely necessary to reliably predict outliers. 

Since there are many missing data, we cannot simply rely on single models for each variable. It is therefore necessary to perform multiple imputation to preserve our dataset. I will use the mice (which stands for Multivariate Imputation by Chained Equations) package which is developed by Stef van Buuren. The basic steps of multiple imputation are described by Rubin (1976). *Citation: Rubin, Donald B. 1976. “Inference and missing data.” Biometrika 63, no. 3: 581-592.*

# Multiple Imputation
*The following text is copied, sometimes verbatim, from the [University of Virgina Library] (https://data.library.virginia.edu/getting-started-with-multiple-imputation-in-r/)* 

1. impute the missing values by using an appropriate model which incorporates random variation.
2. repeat the first step 3-5 times.
3. perform the desired analysis on each data set by using standard, complete data methods.
4. average the values of the parameter estimates across the missing value samples in order to obtain a single point estimate.
5. calculate the standard errors by averaging the squared standard errors of the missing value estimates. After this, calculate the variance of the missing value parameter across the samples. Finally, combine the two quantities in multiple imputation for missing data to calculate the standard errors.

Put in a simpler way, we a) choose values that keep the relationship in the dataset intact in place of missing values b) create independently drawn imputed (usually 5) datasets c) calculate new standard errors using variation across datasets to take into account the uncertainty created by these imputed datasets (Kropko et al. 2014).
*Citation: Kropko, Jonathan, Ben Goodrich, Andrew Gelman, and Jennifer Hill. 2014. “Multiple imputation for continuous and categorical data: Comparing joint multivariate normal and conditional approaches.” Political Analysis 22, no. 4.*

## Missing Data Assumptions
Rubin (1976) classified types of missing data in three categories: MCAR, MAR, MNAR

MCAR: Missing Completely at Random – the reason for the missingness of data points are at random, meaning that the pattern of missing values is uncorrelated with the structure of the data. An example would be a random sample taken from the population: data on some people will be missing, but it will be at random since everyone had the same chance of being included in the sample.

MAR: Missing at Random – the missingness is not completely random, but the propensity of missingness depends on the observed data, not the missing data. An example would be a survey respondent choosing not to answer a question on **income** because they believe the privacy of personal information. As seen in this case, the missing value for income can be predicted by looking at the answers for the personal information question.

MNAR: Missing Not at Random – the missing is not random, it correlates with unobservable characteristics unknown to a researcher. An example would be social desirability bias in survey – where respondents with certain characteristics we can’t observe systematically shy away from answering questions on racial issues.

All multiple imputation techniques start with the MAR assumption. While MCAR is desirable, in general it is unrealistic for the data. Thus, researchers make the assumption that missing values can be replaced by predictions derived by the observable portion of the dataset. This is a fundamental assumption to make, otherwise we wouldn’t be able to predict plausible values of missing data points from the observed data.

There are two approaches to multiple imputation, implemented by different packages in R:

* Joint Multivariate Normal Distribution Multiple Imputation: The main assumption in this technique is that the observed data follows a multivariate normal distribution. Therefore, the algorithm that R packages use to impute the missing values draws values from this assumed distribution. Amelia and norm packages use this technique. The biggest problem with this technique is that the imputed values are incorrect if the data doesn’t follow a multivariate normal distribution.

* Conditional Multiple Imputation: Conditional MI, as indicated in its name, follows an iterative procedure, modeling the conditional distribution of a certain variable given the other variables. This technique allows users to be more flexible as a distribution is assumed for each variable rather than the whole dataset.

If our data appears highly normal, we may use the first option. Let's examine service connections.
```{r}
allSmalls %>% 
ggplot(aes(x = Service_Connections, fill = Fee_Code)) + 
  geom_histogram(position = "stack",alpha=0.6, bins = 100, color = "gray") +
  scale_x_log10() +
  annotation_logticks(base = 10, sides = "b")+ #only bottom
  labs(x='Service Connections',y = "Count",
       title = "Histogram of Water Sytems Considered For Survey Sampling", subtitle = "Sampling strata breaks shown in dotted lines; stacked bins")+
  scale_fill_manual(name = "Fee Code", 
                    labels = c("Large Water System", "Disadvantaged Large Community Water System", "Disadvantaged Small Community Water System", "Small Community"),
                    values = cal_palette("superbloom3"))+
  geom_vline(xintercept = c(1009, 3315, 6360), linetype ='dashed') +
    theme_half_open() +
  theme(legend.position = c(0.01, 0.83),
         legend.box.background = element_rect(color = "black"),
         legend.title = element_text(size = 10, face = "bold", hjust = 0.5),
         legend.text = element_text(size = 7),
         plot.title = element_text(size = 15, face = "bold", hjust = 0.5),
         plot.subtitle = element_text(size = 12, hjust = 0.5, face = "italic"),
         axis.title = element_text(size = 12, face = "bold",),
         axis.text = element_text(size = 12))
```
It's highly unlikely that our data are very non-normal, as implied by the distributions of service connections. Therefore, we will use Conditional MI to impute values. 

![Three main steps to impute data. Source: University of Virgina Library](https://data.library.virginia.edu/files/figure1_mi.jpg)

## Mice Overview
As the first step, the *mice* command creates several complete datasets (in the figure above, n=3). It considers each missing value to follow a specific distribution, and draws from this distribution a plausible value to replace the missing value.

These complete datasets are stored in an object class called *mids*, short for multiply imputed dataset. These datasets are copies of the original dataframe except that missing values are now replaced with values generated by mice. Since these values are generated, they create additional uncertainty about what the real values of these missing data points are. We will need to factor in this uncertainty in the future as we are estimating the regression coefficients from these datasets.

Now that we have 3 complete datasets, the next step is to run an ols regression on all these 3 datasets with 549 observations each (the dataset without incompletes has 182 observations). With *with_mids* command, we run the ols regression and obtain a different regression coefficient for each dataset, reflecting the effect of service connection size on delinquent number of accounts. These 3 coefficients are different from each other because each dataset contains different imputed values, and we are uncertain about which imputed values are the correct ones. The analysis results are stored in a *mira* object class, short for multiply imputed repeated analysis.

Finally, we pool together the 3 coefficients estimated by the imputed dataset into 1 final regression coefficient, and estimate the variance using the *pool* command. With the assumption that regression coefficients are obtained from a multivariate normal distribution, in order to obtain the final coefficient we just take the mean of 3 values. We calculate the variance of the estimated coefficient by factoring in the within (accounting for differences in predicted values from the dataset regarding each observation) and between (accounting for differences between 3 datasets) imputation variance.

## Mice Implementation
First let's start my building an Ordinary Least Squares (OLS) linear regression to predict cash in reserve (total) based on relevant predictors for all systems (e.g. service connections, median 12 month household income, delinquent number of accounts, delinquent amout in dollars, CalEnvrioScreen 3 scores). We will ignore the volunteer data for now. 
```{r}
## Estimate an OLS Regression
fitols <- lm(cash_reserve_total ~ Service_Connections + Population + Median_12month_HH_income +
               Median_rent_pct_income + CES_3.0_Score + delinquent_num_acc +
               delinquent_amount_dollars, na.action = na.omit, 
             data = allSmalls.requested.responded)
summary(fitols)
```
As we can see in the table above, a significant number of observations were deleted due to missingness (76 out of 371). Since this is greater than 14% of the whole dataset, our survey would be limited in power.

Time to impute. First we need to prepare the dataset for imputation. It's best to keep it in it's rawest form, so any categorical factors should be left as so, instead of using the ordinal transformed variable from above. Further, we want to remove variables that have haver than 25% missing values because they may mess up the imputation. It's also important to remove variables that are highly correlated with others so as to stop the imputation working otherwise. Additionally, any extreme outliers should be removed, as they may dramatically impact results.
```{r}
require(reshape2)
allSmalls.requested.responded %>% 
  select(PWSID, Service_Connections,  Median_12month_HH_income, CES_3.0_Score,
         months_before_assist_num, cash_reserve_total, delinquent_num_acc, delinquent_amount_dollars,
         revenue_2020_Total, revenue_2019_Total) %>% 
  melt() %>%  #convert wide to long
  ggplot(aes(x = value)) + 
  stat_density() + 
  facet_wrap(~variable, scales = "free")
```
Everything looks more or less realistic, however would benefit from log10 transformation for visualizing and possibly for statistics. 

```{r,  }
require(reshape2)
allSmalls.requested.responded %>% 
  select(PWSID, Service_Connections,  Median_12month_HH_income, CES_3.0_Score,
         months_before_assist_num, cash_reserve_total, delinquent_num_acc, delinquent_amount_dollars,
         revenue_2020_Total, revenue_2019_Total) %>% 
  mutate_if(~is.numeric(.) && (.) > 0, log10) %>% 
  melt() %>%  #convert wide to long
  ggplot(aes(x = value)) + 
  stat_density() + 
  facet_wrap(~variable, scales = "free")
```
Now distributions look more or less "normal."

```{r,  }
allSmalls.requested.responded %>% 
  filter(cash_reserve_total < 1000000000) %>% 
  ggplot(aes(x = log10(cash_reserve_total ))) + 
  scale_x_continuous(labels = scales::scientific) +
  stat_density()
```
We can see that there is a very wide gap between cash reserves of some systems (nearly 100 million dollars versus majority having less than 1 million). When plotted on a log10 scale, it's easy to see this discrepancy. To ensure these aren't typos, let's take a closer look at these systems.
```{r}
allSmalls.requested.responded %>% 
  #filter(cash_reserve_total > 100000) %>% 
  select(PWSID, cash_reserve_total, Service_Connections, Population, Fee_Code, Regulating_Agency, Water_System_Name, comments_cash_reserves, comments_exp_rev, months_before_assist, delinquent_num_acc) %>% 
  arrange(desc(cash_reserve_total)) %>% 
  head()
```
While it is possible that the Coachella Valley Water District has nearly 100 million dollars in cash reserve, it is an order of magnitude larger than every other system in the survey, yet does have a huge number of service connections. For the sake of imputation, this system will be excluded. 

```{r, results = 'hide'}
p_missing <- unlist(lapply(allSmalls.responded, function(x) sum(is.na(x))))/nrow(smalls)
sort(p_missing[p_missing > 0], decreasing = TRUE)
```
Many of these variables are missing at high rates, such as sub-metered status,and unrestricted cash reserve. I'll remove those. Also, the monetary values are bins and are not "missing" so much as they are just formatted long-wise binary. We'll remove those too.
```{r}
#define sub dataset
allSmalls.simple <- allSmalls.requested.responded %>% 
  select(PWSID, Service_Connections,  Median_12month_HH_income, CES_3.0_Score, months_before_assist, cash_reserve_total, delinquent_num_acc, delinquent_amount_dollars, revenue_2020_Total, revenue_2019_Total)

#split the other half of the dataset for easy joining
allSmalls.rest <- allSmalls %>% 
  filter(requested ==  "y") %>% 
  filter(responded == "y") %>% 
  select(-Service_Connections, -Median_12month_HH_income, -CES_3.0_Score, -months_before_assist, -cash_reserve_total, -delinquent_num_acc, -delinquent_amount_dollars, -revenue_2020_Total, -revenue_2019_Total)
#see missing values
md.pattern(allSmalls.simple)
```
At this step, we need to specify distributions for our to-be imputed variables and determine which variable we would like to leave out of the imputation prediction process. We will extract information on the predictor matrix and imputation methods to change them.

The Predictor Matrix informs us which variables are going to be used to predict a plausible value for variables (1 means a variable is used to predict another variable, 0 otherwise). Since no variable can predict itself, the intersection of one variable with itself in the matrix takes the value 0. We can manually determine if we would like to leave certain variables out of prediction. In this case, we will leave out the risk score which is based on other variables in this survey. 

The *mice* package assumes a distribution for each variable and imputes missing variables according to that distribution. Hence, it is important to correctly specify each of these distributions. *mice* automatically chooses distributions for variables. If we would like to change them, we can do it by changing the methods’ characteristics.
```{r}
# We run the mice code with 0 iterations 
imp <- mice(allSmalls.simple, maxit=0)

# Extract predictorMatrix and methods of imputation 
predM <- imp$predictorMatrix
meth <- imp$method

# Setting values of variables I'd like to leave out to 0 in the predictor matrix
predM[, c("PWSID")] <- 0 #name variable need not be considered
# If you like, view the first few rows of the predictor matrix
#head(predM)

# Specify a separate imputation model for variables of interest 
# Ordered categorical variables 
poly <- c("months_before_assist")

# Dichotomous variable
#log <- c("")

# Unordered categorical variable 
#poly2 <- c("voluntary")

# Turn their methods matrix into the specified imputation models
meth[poly] <- "polr"
#meth[log] <- "logreg"
#meth[poly2] <- "polyreg"
meth
```

Our variables of interest are now configured to be imputed with the imputation method we specified. Empty cells in the method matrix means that those variables aren’t going to be imputed.We are now ready for multiple imputation. This step may take a few minutes.

```{r}
#There is a special function called quickpred() for a quick selection procedure of predictors, which can be handy for datasets containing many variables. selecting predictors according to data relations with a minimum correlation of ρ=.30 can be done by:
ini <- mice(allSmalls.simple, pred=quickpred(allSmalls.simple, mincor=.3), print=F,
            maxit = 20)
plot(ini)
```
Convergence is quite good for some variables (revenue  2020 and 2019 totals,cash reserves), but poor for others. Let's try another imputation process:
```{r}
# With this command, we tell mice to impute the subset data, create 5 datasets, use predM as the predictor matrix and don't print the imputation process. If you would like to see the process, set print as TRUE
imp2 <- mice(allSmalls.simple, 
             maxit =20, #may want to extend to 40
             predictorMatrix = predM, 
             nnet.MaxNWts = 3000, # increase max neural network weights
             method = "cart", #Classification and regression trees method
             print =  FALSE)
plot(imp2)
```


The *mice()* function implements an iterative Markov Chain Monte Carlo type of algorithm. The plots above show the mean(left) and standard deviation(right) of the imputed values. In general, we would like the streams to intermingle and be free of any trends at the later iterations.

Let's run further diagnostics. Generally, one would prefer for the imputed data to be plausible values, i.e. values that could have been observed if they had not been missing. In order to form an idea about plausibility, one may check the imputations and compare them against the observed values. If we are willing to assume that the data are missing completely at random (MCAR), then the imputations should have the same distribution as the observed data. In general, distributions may be different because the missing data are MAR (or even MNAR). However, very large discrepancies need to be screened. Let us plot the observed and imputed data of total cash reserve.
```{r}
# inspect quality of imputations
stripplot(imp2, cash_reserve_total~.imp, pch = 19, xlab = "Imputation number")
```
We can see above that the imputed values are indeed realistic. Let's examine the other variables.
```{r}
stripplot(imp2)
```

Observed data is plotted in blue, and imputed is in red. The figure graphs the data values of chl before and after imputation. Since the PMM method draws imputations from the observed data, imputed values have the same gaps as in the observed data, and are always within the range of the observed data. The figure indicates that the distributions of the imputed and the observed values are similar. The observed data have a particular feature that, for some reason, thedata cluster around the value of ???

Finally, we need to run the regression on each of the 40 datasets and pool the estimates together to get average regression coefficients and correct standard errors. The *with* function in the *mice* package allows us to do this.
```{r}
#First, turn the datasets into long format
allSmalls.simple_long <- mice::complete(imp2, action="long", include = TRUE)

# #provide integer tag for voluntary status
# allSmalls.simple_long %<>% 
#   mutate(volunteered = case_when(voluntary == "y" ~ 1,voluntary == "n" ~ 0))
#provide integer tag for loan status

# Convert back to mids type - mice can work with this type
allSmalls.simple_long_mids <- as.mids(allSmalls.simple_long)
# Regression 

fitimp <- with(allSmalls.simple_long_mids,
  lm(months_before_assist_num ~ Service_Connections + Median_12month_HH_income + Median_rent_pct_income + CES_3.0_Score + delinquent_num_acc + volunteered + delinquent_amount_dollars, na.action = na.omit, data = allSmalls.responded))

summary(pool(fitimp))
```
We can compare the pooled coefficients and p-values from the imputed datasets to see if any trends are altered (either become more pronounced or less). They should be similiar to the listwise-deletion technique.

Let's look at the fmi and lambda. These should be quite low for a good model. 
```{r}
pool(fitimp)
```
We can see that these values are very low. Let's compare to the default model.
```{r}
#First, turn the datasets into long format
allSmalls.simple_long_1 <- mice::complete(imp, action="long", include = TRUE)

# #provide integer tag for voluntary status
# allSmalls.simple_long %<>% 
#   mutate(volunteered = case_when(voluntary == "y" ~ 1,voluntary == "n" ~ 0))
#provide integer tag for loan status

# Convert back to mids type - mice can work with this type
allSmalls.simple_long_mids_1 <- as.mids(allSmalls.simple_long_1)
# Regression 

fitimp_1 <- with(allSmalls.simple_long_mids_1,
  lm(months_before_assist_num ~ Service_Connections + Median_12month_HH_income + Median_rent_pct_income + CES_3.0_Score + delinquent_num_acc + volunteered + delinquent_amount_dollars, na.action = na.omit, data = allSmalls.responded))

summary(pool(fitimp_1))
```
```{r}
pool(fitimp_1)
```
These two models are virtually the same.

Let's further inspect the imputed values by plotting the histograms (using density plots) for the real (blue) and imputed (red) values. 
```{r}
densityplot(imp)
```
Many of these variables seem to be well-predicted by the mode. The worst seems to be CES 3.0 score and 12 month household income. Looking closer.
```{r}
densityplot(imp, ~CES_3.0_Score)
```
We can see here that the model biases towards lower CalEnviroScreen 3.0 scores. 
```{r}
densityplot(imp, ~months_before_assist)
```
This model seems to overestimate the number of systems that will need immediate assistance. 
```{r}
densityplot(imp, ~Median_12month_HH_income)
```
This model has not adequately learned income status.

```{r}
densityplot(imp, ~delinquent_num_acc)
```
Also not great.
```{r}
densityplot(imp, ~revenue_2019_Total)
```
Seems ok.
```{r}
densityplot(imp, ~revenue_2020_Total)
```
Great!

Let's further compare the default imputation method (passive multiple imputation) with the other method employed (Classification and regression trees method) for CES 3.0 score. 
```{r}
CES_3.0_Score <- c(complete(imp)$CES_3.0_Score, complete(imp)$CES_3.0_Score)
method <- rep(c("pmm", "cart"), each = nrow(allSmalls.simple))
CES_3.0_Score_m <- data.frame(CES_3.0_Score = CES_3.0_Score, method = method)
#plot histogram
histogram( ~CES_3.0_Score | method, data = CES_3.0_Score_m, nint = 25)
```
Here we see that passive multiple imputation and the Classification and regression trees method do not seemingly differ in prediction. However, these values were still poorly predicted, so we will not use them further.

Now that we are satisfied with the selected imputed variables for dataset, let's extract the completed data and confirm that there are no additional missing values. 
```{r}
#extract the third imputed data set
simpleImputed <- complete(imp) %>% select(-CES_3.0_Score, -Median_12month_HH_income, -months_before_assist, -Service_Connections)
#the imputed data can also be extracted in long format.
#c.long <- complete(imp, "long")  
md.pattern(simpleImputed)
```
Here we can see that all data is completed.

We can also compare summary statistics for the imputed variables with those in the original dataset.
```{r}
simpleImputed %>% 
  mutate(Grp = "Imputed") %>%
  bind_rows(mutate(allSmalls.requested.responded, Grp = "Original"))  %>%
  select(Grp, delinquent_num_acc, delinquent_amount_dollars, revenue_2020_Total, revenue_2019_Total) %>%
  group_by(Grp) %>% 
  drop_na() %>% 
  summarize_all(list(mean = "mean", median = "median"))
```
Summary stats can be plotted.
```{r}
#join data for plotting
simpleImputed %>% mutate(Grp = "Imputed") %>%
  bind_rows(mutate(allSmalls.requested.responded, Grp = "Original"))  %>%
  select(Grp, delinquent_num_acc, delinquent_amount_dollars, revenue_2020_Total, revenue_2019_Total) %>% 
  melt() %>% #transforms values and variables to long format
  ggplot(aes(x = variable, y = log10(value))) +
  geom_boxplot(aes(fill = Grp))+
  geom_jitter(aes(color = Grp), alpha = 0.3)
```
We can see that imputation has not noticeably changed the summary statistics of these data. We shall now fill in the dataset with these imputed values. 

```{r join imputed data,results= 'hide'}
#join data with imputed values to rest of dataset
imputedSmalls <- right_join(simpleImputed, allSmalls.rest, by = "PWSID")
#also split the dataset that has requested but no response data, which we will only use to adjust weights in the next section
allSmalls.requested.voluntary.rest <- allSmalls.requested.voluntary %>% 
  select(-cash_reserve_total, -delinquent_num_acc, -delinquent_amount_dollars, -revenue_2020_Total, -revenue_2019_Total)
#join
imputedSmalls.requested.voluntary <- right_join(simpleImputed, allSmalls.requested.voluntary.rest, by = "PWSID")
rm(allSmalls.requested.voluntary.rest)
rm(allSmalls.rest)
rm(imp)
rm(imp2)
rm(fitols)
rm(allSmalls.simple2)
rm(allSmalls.simple_long)
rm(allSmalls.simple_long_1)
rm(allSmalls.simple_long_mids)
rm(allSmalls.simple_long_mids_1)
rm(fitimp)
rm(fitimp_1)
rm(ini)
rm(CES_3.0_Score_m)
#visualize remaining missing values
md.pattern(imputedSmalls)
```
Note that some variables are still missing, however these were deliberately not imputed either due to no being applicable (such as binned data) or would were calculated from other variables. 

